{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "708e2ca4",
      "metadata": {
        "id": "708e2ca4"
      },
      "source": [
        "## Sentiment Analysis with Transformers\n",
        "In this notebook, we will fine-tune a pre-trained transformer model for sentiment analysis using a custom dataset of tweets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "ZZTd1ExyTPii"
      },
      "id": "ZZTd1ExyTPii",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('./ML Assignment Dataset - Train.csv')\n",
        "df.rename(columns={\n",
        "    'tweet_text': 'text',\n",
        "    'emotion_in_tweet_is_directed_at': 'brand',\n",
        "    'is_there_an_emotion_directed_at_a_brand_or_product': 'emotion'\n",
        "}, inplace=True)\n",
        "\n",
        "# Map the emotion labels to categories\n",
        "def map_to_categories(label):\n",
        "    if label in ['Negative emotion', 'negative']:\n",
        "        return 'negative'\n",
        "    elif label in ['Positive emotion', 'positive']:\n",
        "        return 'positive'\n",
        "    else:\n",
        "        return 'neutral'\n",
        "df['emotion'] = df['emotion'].apply(map_to_categories)"
      ],
      "metadata": {
        "id": "3eigOjAyTREE"
      },
      "id": "3eigOjAyTREE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('brand', axis=1, inplace=True)\n",
        "df = df.dropna(subset=['text'])"
      ],
      "metadata": {
        "id": "ooflSPXMTT-j"
      },
      "id": "ooflSPXMTT-j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('wysa.csv', index=False)"
      ],
      "metadata": {
        "id": "2XPZ2HefTVW8"
      },
      "id": "2XPZ2HefTVW8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9X5-hkVPn-p"
      },
      "source": [
        "### Run the code from here once csv is saved locally"
      ],
      "id": "i9X5-hkVPn-p"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Cgab70FyPn-q"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "id": "Cgab70FyPn-q"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-iGulHePn-q",
        "outputId": "8961c7c4-ed84-455a-8dc7-118071b699e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8588, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Load CSV data\n",
        "df = pd.read_csv('./wysa.csv')\n",
        "df.shape"
      ],
      "id": "V-iGulHePn-q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfY_kojEPn-s"
      },
      "source": [
        "Augmentation of df using synonym replacement"
      ],
      "id": "EfY_kojEPn-s"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5hC_NONPn-s",
        "outputId": "e6b74b02-055a-4900-ef0b-7167466d53db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import random\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "\n",
        "# Function to augment text data using synonym replacement\n",
        "def synonym_replacement(text, n):\n",
        "    words = text.split()\n",
        "    new_words = words.copy()\n",
        "    random_word_list = list(set([word for word in words if wordnet.synsets(word)]))\n",
        "    random.shuffle(random_word_list)\n",
        "    num_replaced = 0\n",
        "    for random_word in random_word_list:\n",
        "        synonyms = wordnet.synsets(random_word)\n",
        "        if len(synonyms) >= 1:\n",
        "            synonym = random.choice(synonyms).lemmas()[0].name()\n",
        "            new_words = [synonym if word == random_word else word for word in new_words]\n",
        "            num_replaced += 1\n",
        "        if num_replaced >= n:\n",
        "            break\n",
        "\n",
        "    sentence = ' '.join(new_words)\n",
        "    return sentence\n",
        "\n",
        "# Augment the dataset\n",
        "augmented_texts = []\n",
        "augmented_labels = []\n",
        "for _, row in df.iterrows():\n",
        "    augmented_texts.append(row['text'])\n",
        "    augmented_labels.append(row['emotion'])\n",
        "    for _ in range(1):  # Augment each entry once\n",
        "        aug_text = synonym_replacement(row['text'], n=2)  # Replace up to 2 words\n",
        "        augmented_texts.append(aug_text)\n",
        "        augmented_labels.append(row['emotion'])\n",
        "\n",
        "augmented_df = pd.DataFrame({'text': augmented_texts, 'emotion': augmented_labels})"
      ],
      "id": "b5hC_NONPn-s"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdCLfzmhPn-t",
        "outputId": "3ffe3409-aac9-448d-b3e5-c78c81a6721f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17176, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "augmented_df.shape"
      ],
      "id": "FdCLfzmhPn-t"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PEC61kZPn-u",
        "outputId": "d73e6b83-2ced-4990-83a2-7d0f33600f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Encode the labels (emotion) into numerical format\n",
        "label_encoder = LabelEncoder()\n",
        "augmented_df['label'] = label_encoder.fit_transform(augmented_df['emotion'])\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "train_df, test_df = train_test_split(augmented_df, test_size=0.2)\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "bert_model_name = \"bert-base-uncased\"\n",
        "model = TFAutoModel.from_pretrained(bert_model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(bert_model_name)"
      ],
      "id": "2PEC61kZPn-u"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gevD3k1PPn-u"
      },
      "outputs": [],
      "source": [
        "# Tokenization and dataset preparation\n",
        "def tokenize_and_format(df):\n",
        "    tokenized = tokenizer(list(df['text']), padding=True, truncation=True, max_length=512, return_tensors='tf')\n",
        "    return tokenized.data, tf.convert_to_tensor(df['label'])\n",
        "\n",
        "train_data, train_labels = tokenize_and_format(train_df)\n",
        "test_data, test_labels = tokenize_and_format(test_df)"
      ],
      "id": "gevD3k1PPn-u"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qq8vGM4Pn-v",
        "outputId": "5966f855-f81d-4b2c-fae7-d3d7f1514b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "859/859 [==============================] - 248s 241ms/step - loss: 0.6302 - accuracy: 0.7268\n",
            "Epoch 2/3\n",
            "859/859 [==============================] - 205s 238ms/step - loss: 0.4058 - accuracy: 0.8419\n",
            "Epoch 3/3\n",
            "859/859 [==============================] - 201s 234ms/step - loss: 0.2585 - accuracy: 0.9035\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e868fd22b30>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Create TensorFlow datasets\n",
        "BATCH_SIZE = 16\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels)).shuffle(len(train_df)).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels)).batch(BATCH_SIZE)\n",
        "\n",
        "# Define a custom BERT-based classification model\n",
        "class BERTForClassification(tf.keras.Model):\n",
        "    def __init__(self, bert_model, num_classes):\n",
        "        super().__init__()\n",
        "        self.bert = bert_model\n",
        "        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.bert(inputs)[1]\n",
        "        return self.fc(x)\n",
        "\n",
        "# Compile and train the classifier\n",
        "num_classes = 3  # Positive, Negative, Neutral\n",
        "classifier = BERTForClassification(model, num_classes=num_classes)\n",
        "classifier.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "                   loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "classifier.fit(train_dataset, epochs=3)"
      ],
      "id": "-qq8vGM4Pn-v"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yS0MXtSSPn-v",
        "outputId": "55d55e8e-f02c-4dac-a563-c6b742364fb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215/215 [==============================] - 20s 76ms/step - loss: 0.3286 - accuracy: 0.8696\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3285703957080841, 0.8696158528327942]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "classifier.evaluate(test_dataset)"
      ],
      "id": "yS0MXtSSPn-v"
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.save('./bert_emotion_classifier')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBu6lrO3SC6m",
        "outputId": "386535fb-2500-4b41-a2c4-de26c25a1324"
      },
      "id": "JBu6lrO3SC6m",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxfD9n2rPn-w",
        "outputId": "56d25850-9004-410a-e493-5fb485d2c1ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Emotion: negative\n"
          ]
        }
      ],
      "source": [
        "def predict_emotion(text, model, tokenizer, label_encoder):\n",
        "    # Tokenize the input text\n",
        "    tokenized_input = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors='tf')\n",
        "\n",
        "    # Predict\n",
        "    prediction = model(tokenized_input)\n",
        "\n",
        "    # Convert the prediction tensor to a numpy array and get the index of the maximum value\n",
        "    # Ensure the prediction is reshaped into a suitable format if needed\n",
        "    predicted_label_index = tf.argmax(prediction, axis=1).numpy()[0]\n",
        "\n",
        "    # Convert the index to the corresponding emotion label\n",
        "    predicted_label = label_encoder.inverse_transform([predicted_label_index])[0]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "# Example usage\n",
        "sample_text = \"you are a murderer!\"\n",
        "predicted_emotion = predict_emotion(sample_text, classifier, tokenizer, label_encoder)\n",
        "print(f\"Predicted Emotion: {predicted_emotion}\")"
      ],
      "id": "RxfD9n2rPn-w"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BXcC9t8LPn-w"
      },
      "outputs": [],
      "source": [],
      "id": "BXcC9t8LPn-w"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}